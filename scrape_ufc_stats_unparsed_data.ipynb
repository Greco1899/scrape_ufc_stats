{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nOverview\\nrun the notebook 'scape_ufc_stats_all_historical_data.ipynb' first to parse all available past data\\n\\nthis code checks existing files for previously parsed data\\nif there are no new or unparsed events, script stops\\n\\nif there are any unparsed events, script continues with parsing\\ncombine new data and existing data into one and write to file\\n\\nthis notebook can be run manually when desired\\nthe script, 'scrape_ufc_stats_unparsed_data.py' is the same code that can be set to run on a schedule\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Overview\n",
    "run the notebook 'scape_ufc_stats_all_historical_data.ipynb' first to parse all available past data\n",
    "\n",
    "this code checks existing files for previously parsed data\n",
    "if there are no new or unparsed events, script stops\n",
    "\n",
    "if there are any unparsed events, script continues with parsing\n",
    "combine new data and existing data into one and write to file\n",
    "\n",
    "this notebook can be run manually when desired\n",
    "the script, 'scrape_ufc_stats_unparsed_data.py' is the same code that can be set to run on a schedule\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "# import library\n",
    "import scrape_ufc_stats_library as LIB\n",
    "\n",
    "# import config\n",
    "import yaml\n",
    "config = yaml.safe_load(open('scrape_ufc_stats_config.yaml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['UFC Fight Night: Kattar vs. Chikadze']\n"
     ]
    }
   ],
   "source": [
    "### check if there are any unparsed events ###\n",
    "\n",
    "# read existing event details\n",
    "parsed_event_details_df = pd.read_csv(config['event_details_file_name'])\n",
    "# get list of parsed event names\n",
    "list_of_parsed_events = list(parsed_event_details_df['EVENT'])\n",
    "\n",
    "# get soup\n",
    "soup = LIB.get_soup(config['completed_events_all_url'])\n",
    "# parse event details\n",
    "updated_event_details_df = LIB.parse_event_details(soup)\n",
    "# get list of all event names\n",
    "list_of_all_events = list(updated_event_details_df['EVENT'])\n",
    "\n",
    "# find list event names that have not been parsed\n",
    "list_of_unparsed_events = [event for event in list_of_all_events if event not in list_of_parsed_events]\n",
    "\n",
    "# check if there are any unparsed events\n",
    "unparsed_events = False\n",
    "# if list_of_unparsed_events is empty then all available events have been parsed\n",
    "if not list_of_unparsed_events:\n",
    "    print('All available events have been parsed.')\n",
    "else:\n",
    "    # set unparsed_events to true\n",
    "    unparsed_events = True\n",
    "    # show list of unparsed events\n",
    "    print(list_of_unparsed_events)\n",
    "    # write event details to file\n",
    "    # updated_event_details_df.to_csv(config['event_details_file_name'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b0603bd43744ded88727531d18e30f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63edfcc8d8b7417eb596815e7e9158d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### parse all missing events ###\n",
    "# if unparsed_events = True\n",
    "# the code below continues to run to parse all missing events\n",
    "# new data is added to existing data and is written to file\n",
    "\n",
    "if unparsed_events == True:\n",
    "    # read existing data files\n",
    "    parsed_fight_details_df = pd.read_csv(config['fight_details_file_name'])\n",
    "    parsed_fight_results_df = pd.read_csv(config['fight_results_file_name'])\n",
    "    parsed_fight_stats_df = pd.read_csv(config['fight_stats_file_name'])\n",
    "\n",
    "    ### parse fight details ###\n",
    "\n",
    "    # define list of urls of missing fights to parse\n",
    "    list_of_unparsed_events_urls = list(updated_event_details_df['URL'].loc[(updated_event_details_df['EVENT'].isin(list_of_unparsed_events))])\n",
    "\n",
    "    # create empty df to store fight details\n",
    "    unparsed_fight_details_df = pd.DataFrame(columns=config['fight_details_column_names'])\n",
    "\n",
    "    # loop through each event and parse fight details\n",
    "    for url in tqdm_notebook(list_of_unparsed_events_urls):\n",
    "\n",
    "        # get soup\n",
    "        soup = LIB.get_soup(url)\n",
    "\n",
    "        # parse fight links\n",
    "        fight_details_df = LIB.parse_fight_details(soup)\n",
    "        \n",
    "        # concat fight details to parsed fight details\n",
    "        # concat update fight details to the top of existing df\n",
    "        unparsed_fight_details_df = pd.concat([unparsed_fight_details_df, fight_details_df])\n",
    "\n",
    "    # concat unparsed and parsed fight details\n",
    "    parsed_fight_details_df = pd.concat([unparsed_fight_details_df, parsed_fight_details_df])\n",
    "\n",
    "    # write fight details to file\n",
    "    # parsed_fight_details_df.to_csv(config['fight_details_file_name'], index=False)\n",
    "\n",
    "    ### parse fight results and fight stats\n",
    "\n",
    "    # define list of urls of fights to parse\n",
    "    list_of_unparsed_fight_details_urls = list(unparsed_fight_details_df['URL'])\n",
    "\n",
    "    # create empty df to store fight results\n",
    "    unparsed_fight_results_df = pd.DataFrame(columns=config['fight_results_column_names'])\n",
    "    # create empty df to store fight stats\n",
    "    unparsed_fight_stats_df = pd.DataFrame(columns=config['fight_stats_column_names'])\n",
    "\n",
    "    # loop through each fight and parse fight results and stats\n",
    "    for url in tqdm_notebook(list_of_unparsed_fight_details_urls):\n",
    "\n",
    "        # get soup\n",
    "        soup = LIB.get_soup(url)\n",
    "\n",
    "        # parse fight results and fight stats\n",
    "        fight_results_df, fight_stats_df = LIB.parse_organise_fight_results_and_stats(\n",
    "            soup,\n",
    "            url,\n",
    "            config['fight_results_column_names'],\n",
    "            config['totals_column_names'],\n",
    "            config['significant_strikes_column_names']\n",
    "            )\n",
    "\n",
    "        # concat fight results\n",
    "        unparsed_fight_results_df = pd.concat([unparsed_fight_results_df, fight_results_df])\n",
    "        # concat fight stats\n",
    "        unparsed_fight_stats_df = pd.concat([unparsed_fight_stats_df, fight_stats_df])\n",
    "\n",
    "    # concat unparsed fight results and fight stats to parsed fight results and fight stats\n",
    "    parsed_fight_results_df = pd.concat([unparsed_fight_results_df, parsed_fight_results_df])\n",
    "    parsed_fight_stats_df = pd.concat([unparsed_fight_stats_df, parsed_fight_stats_df])\n",
    "\n",
    "    # write to file\n",
    "    # parsed_fight_results_df.to_csv(config['fight_results_file_name'], index=False)\n",
    "    # write to file\n",
    "    # parsed_fight_stats_df.to_csv(config['fight_stats_file_name'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9aac8944d03ded7dbafcde28cbfe34d23c9079c2df9125865de5144d9ea8ac9a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
